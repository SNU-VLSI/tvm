type List[A] {
  Cons(A, List[A]),
  Nil,
}

type Option[A] {
  Some(A),
  None,
}

type Tree[A] {
  Rose(A, List[Tree[A]]),
}

type tensor_float16_t {
  tensor_nil_float16,
  tensor0_float16(float16),
  tensor1_float16(Tensor[(?), float16]),
  tensor2_float16(Tensor[(?, ?), float16]),
  tensor3_float16(Tensor[(?, ?, ?), float16]),
  tensor4_float16(Tensor[(?, ?, ?, ?), float16]),
  tensor5_float16(Tensor[(?, ?, ?, ?, ?), float16]),
  tensor6_float16(Tensor[(?, ?, ?, ?, ?, ?), float16]),
}

type tensor_float32_t {
  tensor_nil_float32,
  tensor0_float32(float32),
  tensor1_float32(Tensor[(?), float32]),
  tensor2_float32(Tensor[(?, ?), float32]),
  tensor3_float32(Tensor[(?, ?, ?), float32]),
  tensor4_float32(Tensor[(?, ?, ?, ?), float32]),
  tensor5_float32(Tensor[(?, ?, ?, ?, ?), float32]),
  tensor6_float32(Tensor[(?, ?, ?, ?, ?, ?), float32]),
}

type tensor_float64_t {
  tensor_nil_float64,
  tensor0_float64(float64),
  tensor1_float64(Tensor[(?), float64]),
  tensor2_float64(Tensor[(?, ?), float64]),
  tensor3_float64(Tensor[(?, ?, ?), float64]),
  tensor4_float64(Tensor[(?, ?, ?, ?), float64]),
  tensor5_float64(Tensor[(?, ?, ?, ?, ?), float64]),
  tensor6_float64(Tensor[(?, ?, ?, ?, ?, ?), float64]),
}

type tensor_int16_t {
  tensor_nil_int16,
  tensor0_int16(int16),
  tensor1_int16(Tensor[(?), int16]),
  tensor2_int16(Tensor[(?, ?), int16]),
  tensor3_int16(Tensor[(?, ?, ?), int16]),
  tensor4_int16(Tensor[(?, ?, ?, ?), int16]),
  tensor5_int16(Tensor[(?, ?, ?, ?, ?), int16]),
  tensor6_int16(Tensor[(?, ?, ?, ?, ?, ?), int16]),
}

type tensor_int32_t {
  tensor_nil_int32,
  tensor0_int32(int32),
  tensor1_int32(Tensor[(?), int32]),
  tensor2_int32(Tensor[(?, ?), int32]),
  tensor3_int32(Tensor[(?, ?, ?), int32]),
  tensor4_int32(Tensor[(?, ?, ?, ?), int32]),
  tensor5_int32(Tensor[(?, ?, ?, ?, ?), int32]),
  tensor6_int32(Tensor[(?, ?, ?, ?, ?, ?), int32]),
}

type tensor_int64_t {
  tensor_nil_int64,
  tensor0_int64(int64),
  tensor1_int64(Tensor[(?), int64]),
  tensor2_int64(Tensor[(?, ?), int64]),
  tensor3_int64(Tensor[(?, ?, ?), int64]),
  tensor4_int64(Tensor[(?, ?, ?, ?), int64]),
  tensor5_int64(Tensor[(?, ?, ?, ?, ?), int64]),
  tensor6_int64(Tensor[(?, ?, ?, ?, ?, ?), int64]),
}

type tensor_int8_t {
  tensor_nil_int8,
  tensor0_int8(int8),
  tensor1_int8(Tensor[(?), int8]),
  tensor2_int8(Tensor[(?, ?), int8]),
  tensor3_int8(Tensor[(?, ?, ?), int8]),
  tensor4_int8(Tensor[(?, ?, ?, ?), int8]),
  tensor5_int8(Tensor[(?, ?, ?, ?, ?), int8]),
  tensor6_int8(Tensor[(?, ?, ?, ?, ?, ?), int8]),
}

type tensor_uint16_t {
  tensor_nil_uint16,
  tensor0_uint16(uint16),
  tensor1_uint16(Tensor[(?), uint16]),
  tensor2_uint16(Tensor[(?, ?), uint16]),
  tensor3_uint16(Tensor[(?, ?, ?), uint16]),
  tensor4_uint16(Tensor[(?, ?, ?, ?), uint16]),
  tensor5_uint16(Tensor[(?, ?, ?, ?, ?), uint16]),
  tensor6_uint16(Tensor[(?, ?, ?, ?, ?, ?), uint16]),
}

type tensor_uint8_t {
  tensor_nil_uint8,
  tensor0_uint8(uint8),
  tensor1_uint8(Tensor[(?), uint8]),
  tensor2_uint8(Tensor[(?, ?), uint8]),
  tensor3_uint8(Tensor[(?, ?, ?), uint8]),
  tensor4_uint8(Tensor[(?, ?, ?, ?), uint8]),
  tensor5_uint8(Tensor[(?, ?, ?, ?, ?), uint8]),
  tensor6_uint8(Tensor[(?, ?, ?, ?, ?, ?), uint8]),
}

def @main(%input0: Tensor[(1, 64, 28, 28), float32] /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::split_with_sizes_0.input0:0:0 */) -> Tensor[(1, 128, 28, 28), float32] {
  %0 = @tvmgen_default_imcflow_region2_main_0(%input0) /* ty=Tensor[(1, 128, 28, 28), float32] */;
  @tvmgen_default_imcflow_region1_main_1(%0) /* ty=Tensor[(1, 128, 28, 28), float32] */
}

def @tvmgen_default_imcflow_region1_main_1(%imcflow_region1_1_i0: Tensor[(1, 128, 28, 28), float32] /* ty=Tensor[(1, 128, 28, 28), float32] */, Compiler="imcflow_region1", Primitive=1, Inline=1, global_symbol="tvmgen_default_imcflow_region1_main_1") -> Tensor[(1, 128, 28, 28), float32] {
  %10 = split(%imcflow_region1_1_i0, indices_or_sections=[meta[runtime.BoxInt][0], meta[runtime.BoxInt][1], meta[runtime.BoxInt][2], meta[runtime.BoxInt][3]], axis=1) /* ty=(Tensor[(1, 28, 28, 28), float32], Tensor[(1, 28, 28, 28), float32], Tensor[(1, 28, 28, 28), float32], Tensor[(1, 28, 28, 28), float32], Tensor[(1, 16, 28, 28), float32]) */;
  %12 = %10.1 /* ty=Tensor[(1, 28, 28, 28), float32] */;
  %13 = fn (%FunctionVar_3_0: Tensor[(1, 28, 28, 28), float32] /* ty=Tensor[(1, 28, 28, 28), float32] */, PartitionedFromPattern="nn.conv2d_nn.bias_add_", Composite="imcflow.conv2d-bias_add") -> Tensor[(1, 64, 28, 28), float32] {
    %11 = nn.conv2d(%FunctionVar_3_0, meta[relay.Constant][6] /* ty=Tensor[(64, 28, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_7:0:0 */;
    nn.bias_add(%11, meta[relay.Constant][7] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_7:0:0 */
  } /* ty=fn (Tensor[(1, 28, 28, 28), float32]) -> Tensor[(1, 64, 28, 28), float32] */;
  %18 = %10.3 /* ty=Tensor[(1, 28, 28, 28), float32] */;
  %19 = fn (%FunctionVar_2_0: Tensor[(1, 28, 28, 28), float32] /* ty=Tensor[(1, 28, 28, 28), float32] */, PartitionedFromPattern="nn.conv2d_nn.bias_add_", Composite="imcflow.conv2d-bias_add") -> Tensor[(1, 64, 28, 28), float32] {
    %17 = nn.conv2d(%FunctionVar_2_0, meta[relay.Constant][10] /* ty=Tensor[(64, 28, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_9:0:0 */;
    nn.bias_add(%17, meta[relay.Constant][11] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_9:0:0 */
  } /* ty=fn (Tensor[(1, 28, 28, 28), float32]) -> Tensor[(1, 64, 28, 28), float32] */;
  %20 = %10.2 /* ty=Tensor[(1, 28, 28, 28), float32] */;
  %21 = %19(%18) /* ty=Tensor[(1, 64, 28, 28), float32] */;
  %22 = fn (%FunctionVar_1_01: Tensor[(1, 28, 28, 28), float32] /* ty=Tensor[(1, 28, 28, 28), float32] */, %FunctionVar_1_11: Tensor[(1, 64, 28, 28), float32] /* ty=Tensor[(1, 64, 28, 28), float32] */, PartitionedFromPattern="nn.conv2d_nn.bias_add_add_divide_", Composite="imcflow.conv2d-bias_add-add-div") -> Tensor[(1, 64, 28, 28), float32] {
    %14 = nn.conv2d(%FunctionVar_1_01, meta[relay.Constant][8] /* ty=Tensor[(64, 28, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_8:0:0 */;
    %15 = nn.bias_add(%14, meta[relay.Constant][9] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_8:0:0 */;
    %16 = add(%15, %FunctionVar_1_11) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::add_5:0:0 */;
    divide(%16, 2f /* ty=float32 span=aten::div_5:0:0 */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::div_5:0:0 */
  } /* ty=fn (Tensor[(1, 28, 28, 28), float32], Tensor[(1, 64, 28, 28), float32]) -> Tensor[(1, 64, 28, 28), float32] */;
  %25 = %10.4 /* ty=Tensor[(1, 16, 28, 28), float32] */;
  %26 = fn (%FunctionVar_1_02: Tensor[(1, 16, 28, 28), float32] /* ty=Tensor[(1, 16, 28, 28), float32] */, PartitionedFromPattern="nn.conv2d_nn.bias_add_divide_", Composite="imcflow.conv2d-bias_add-div") -> Tensor[(1, 64, 28, 28), float32] {
    %23 = nn.conv2d(%FunctionVar_1_02, meta[relay.Constant][12] /* ty=Tensor[(64, 16, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_10:0:0 */;
    %24 = nn.bias_add(%23, meta[relay.Constant][13] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_10:0:0 */;
    divide(%24, 2f /* ty=float32 span=aten::div_6:0:0 */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::div_6:0:0 */
  } /* ty=fn (Tensor[(1, 16, 28, 28), float32]) -> Tensor[(1, 64, 28, 28), float32] */;
  %27 = %10.0 /* ty=Tensor[(1, 28, 28, 28), float32] */;
  %28 = %13(%12) /* ty=Tensor[(1, 64, 28, 28), float32] */;
  %29 = %22(%20, %21) /* ty=Tensor[(1, 64, 28, 28), float32] */;
  %30 = %26(%25) /* ty=Tensor[(1, 64, 28, 28), float32] */;
  %31 = fn (%FunctionVar_1_0: Tensor[(1, 28, 28, 28), float32] /* ty=Tensor[(1, 28, 28, 28), float32] */, %FunctionVar_1_1: Tensor[(1, 64, 28, 28), float32] /* ty=Tensor[(1, 64, 28, 28), float32] */, %FunctionVar_1_2: Tensor[(1, 64, 28, 28), float32] /* ty=Tensor[(1, 64, 28, 28), float32] */, %FunctionVar_1_3: Tensor[(1, 64, 28, 28), float32] /* ty=Tensor[(1, 64, 28, 28), float32] */, PartitionedFromPattern="nn.conv2d_nn.bias_add_add_divide_add_add_nn.batch_norm_TupleGetItem0_nn.relu_qnn.imcflow_min_max_quantize_", Composite="imcflow.conv2d-bias_add-add-div-add-bn-relu-min_max_quant") -> Tensor[(1, 64, 28, 28), float32] {
    %1 = nn.conv2d(%FunctionVar_1_0, meta[relay.Constant][0] /* ty=Tensor[(64, 28, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_6:0:0 */;
    %2 = nn.bias_add(%1, meta[relay.Constant][1] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_6:0:0 */;
    %3 = add(%2, %FunctionVar_1_1) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::add_4:0:0 */;
    %4 = divide(%3, 2f /* ty=float32 span=aten::div_4:0:0 */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::div_4:0:0 */;
    %5 = add(%4, %FunctionVar_1_2) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::add_6:0:0 */;
    %6 = add(%5, %FunctionVar_1_3) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::add_7:0:0 */;
    %7 = nn.batch_norm(%6, meta[relay.Constant][2] /* ty=Tensor[(64), float32] */, meta[relay.Constant][3] /* ty=Tensor[(64), float32] */, meta[relay.Constant][4] /* ty=Tensor[(64), float32] */, meta[relay.Constant][5] /* ty=Tensor[(64), float32] */) /* ty=(Tensor[(1, 64, 28, 28), float32], Tensor[(64), float32], Tensor[(64), float32]) span=aten::batch_norm_2:0:0 */;
    %8 = %7.0 /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::batch_norm_2:0:0 */;
    %9 = nn.relu(%8) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::relu_2:0:0 */;
    qnn.imcflow_min_max_quantize(%9, 0f /* ty=float32 span=imcflow::min_max_quant_2:0:0 */, 1f /* ty=float32 span=imcflow::min_max_quant_2:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 64, 28, 28), float32] span=imcflow::min_max_quant_2:0:0 */
  } /* ty=fn (Tensor[(1, 28, 28, 28), float32], Tensor[(1, 64, 28, 28), float32], Tensor[(1, 64, 28, 28), float32], Tensor[(1, 64, 28, 28), float32]) -> Tensor[(1, 64, 28, 28), float32] */;
  %42 = fn (%FunctionVar_1_03: Tensor[(1, 28, 28, 28), float32] /* ty=Tensor[(1, 28, 28, 28), float32] */, PartitionedFromPattern="nn.conv2d_nn.bias_add_", Composite="imcflow.conv2d-bias_add") -> Tensor[(1, 64, 28, 28), float32] {
    %41 = nn.conv2d(%FunctionVar_1_03, meta[relay.Constant][20] /* ty=Tensor[(64, 28, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_12:0:0 */;
    nn.bias_add(%41, meta[relay.Constant][21] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_12:0:0 */
  } /* ty=fn (Tensor[(1, 28, 28, 28), float32]) -> Tensor[(1, 64, 28, 28), float32] */;
  %47 = fn (%FunctionVar_0_02: Tensor[(1, 28, 28, 28), float32] /* ty=Tensor[(1, 28, 28, 28), float32] */, PartitionedFromPattern="nn.conv2d_nn.bias_add_", Composite="imcflow.conv2d-bias_add") -> Tensor[(1, 64, 28, 28), float32] {
    %46 = nn.conv2d(%FunctionVar_0_02, meta[relay.Constant][24] /* ty=Tensor[(64, 28, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_14:0:0 */;
    nn.bias_add(%46, meta[relay.Constant][25] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_14:0:0 */
  } /* ty=fn (Tensor[(1, 28, 28, 28), float32]) -> Tensor[(1, 64, 28, 28), float32] */;
  %48 = %47(%18) /* ty=Tensor[(1, 64, 28, 28), float32] */;
  %49 = fn (%FunctionVar_0_01: Tensor[(1, 28, 28, 28), float32] /* ty=Tensor[(1, 28, 28, 28), float32] */, %FunctionVar_0_11: Tensor[(1, 64, 28, 28), float32] /* ty=Tensor[(1, 64, 28, 28), float32] */, PartitionedFromPattern="nn.conv2d_nn.bias_add_add_divide_", Composite="imcflow.conv2d-bias_add-add-div") -> Tensor[(1, 64, 28, 28), float32] {
    %43 = nn.conv2d(%FunctionVar_0_01, meta[relay.Constant][22] /* ty=Tensor[(64, 28, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_13:0:0 */;
    %44 = nn.bias_add(%43, meta[relay.Constant][23] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_13:0:0 */;
    %45 = add(%44, %FunctionVar_0_11) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::add_9:0:0 */;
    divide(%45, 2f /* ty=float32 span=aten::div_8:0:0 */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::div_8:0:0 */
  } /* ty=fn (Tensor[(1, 28, 28, 28), float32], Tensor[(1, 64, 28, 28), float32]) -> Tensor[(1, 64, 28, 28), float32] */;
  %52 = fn (%FunctionVar_0_03: Tensor[(1, 16, 28, 28), float32] /* ty=Tensor[(1, 16, 28, 28), float32] */, PartitionedFromPattern="nn.conv2d_nn.bias_add_divide_", Composite="imcflow.conv2d-bias_add-div") -> Tensor[(1, 64, 28, 28), float32] {
    %50 = nn.conv2d(%FunctionVar_0_03, meta[relay.Constant][26] /* ty=Tensor[(64, 16, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_15:0:0 */;
    %51 = nn.bias_add(%50, meta[relay.Constant][27] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_15:0:0 */;
    divide(%51, 2f /* ty=float32 span=aten::div_9:0:0 */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::div_9:0:0 */
  } /* ty=fn (Tensor[(1, 16, 28, 28), float32]) -> Tensor[(1, 64, 28, 28), float32] */;
  %53 = %42(%12) /* ty=Tensor[(1, 64, 28, 28), float32] */;
  %54 = %49(%20, %48) /* ty=Tensor[(1, 64, 28, 28), float32] */;
  %55 = %52(%25) /* ty=Tensor[(1, 64, 28, 28), float32] */;
  %56 = fn (%FunctionVar_0_0: Tensor[(1, 28, 28, 28), float32] /* ty=Tensor[(1, 28, 28, 28), float32] */, %FunctionVar_0_1: Tensor[(1, 64, 28, 28), float32] /* ty=Tensor[(1, 64, 28, 28), float32] */, %FunctionVar_0_2: Tensor[(1, 64, 28, 28), float32] /* ty=Tensor[(1, 64, 28, 28), float32] */, %FunctionVar_0_3: Tensor[(1, 64, 28, 28), float32] /* ty=Tensor[(1, 64, 28, 28), float32] */, PartitionedFromPattern="nn.conv2d_nn.bias_add_add_divide_add_add_nn.batch_norm_TupleGetItem0_nn.relu_qnn.imcflow_min_max_quantize_", Composite="imcflow.conv2d-bias_add-add-div-add-bn-relu-min_max_quant") -> Tensor[(1, 64, 28, 28), float32] {
    %32 = nn.conv2d(%FunctionVar_0_0, meta[relay.Constant][14] /* ty=Tensor[(64, 28, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_11:0:0 */;
    %33 = nn.bias_add(%32, meta[relay.Constant][15] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_11:0:0 */;
    %34 = add(%33, %FunctionVar_0_1) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::add_8:0:0 */;
    %35 = divide(%34, 2f /* ty=float32 span=aten::div_7:0:0 */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::div_7:0:0 */;
    %36 = add(%35, %FunctionVar_0_2) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::add_10:0:0 */;
    %37 = add(%36, %FunctionVar_0_3) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::add_11:0:0 */;
    %38 = nn.batch_norm(%37, meta[relay.Constant][16] /* ty=Tensor[(64), float32] */, meta[relay.Constant][17] /* ty=Tensor[(64), float32] */, meta[relay.Constant][18] /* ty=Tensor[(64), float32] */, meta[relay.Constant][19] /* ty=Tensor[(64), float32] */) /* ty=(Tensor[(1, 64, 28, 28), float32], Tensor[(64), float32], Tensor[(64), float32]) span=aten::batch_norm_3:0:0 */;
    %39 = %38.0 /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::batch_norm_3:0:0 */;
    %40 = nn.relu(%39) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::relu_3:0:0 */;
    qnn.imcflow_min_max_quantize(%40, 0f /* ty=float32 span=imcflow::min_max_quant_3:0:0 */, 1f /* ty=float32 span=imcflow::min_max_quant_3:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 64, 28, 28), float32] span=imcflow::min_max_quant_3:0:0 */
  } /* ty=fn (Tensor[(1, 28, 28, 28), float32], Tensor[(1, 64, 28, 28), float32], Tensor[(1, 64, 28, 28), float32], Tensor[(1, 64, 28, 28), float32]) -> Tensor[(1, 64, 28, 28), float32] */;
  %57 = %31(%27, %28, %29, %30) /* ty=Tensor[(1, 64, 28, 28), float32] */;
  %58 = %56(%27, %53, %54, %55) /* ty=Tensor[(1, 64, 28, 28), float32] */;
  %59 = (%57, %58) /* ty=(Tensor[(1, 64, 28, 28), float32], Tensor[(1, 64, 28, 28), float32]) */;
  concatenate(%59, axis=1) /* ty=Tensor[(1, 128, 28, 28), float32] */
}

def @tvmgen_default_imcflow_region2_main_0(%imcflow_region2_0_i0: Tensor[(1, 64, 28, 28), float32] /* ty=Tensor[(1, 64, 28, 28), float32] */, Compiler="imcflow_region2", Primitive=1, Inline=1, global_symbol="tvmgen_default_imcflow_region2_main_0") -> Tensor[(1, 128, 28, 28), float32] {
  %68 = split(%imcflow_region2_0_i0, indices_or_sections=[meta[runtime.BoxInt][4], meta[runtime.BoxInt][5]], axis=1) /* ty=(Tensor[(1, 28, 28, 28), float32], Tensor[(1, 28, 28, 28), float32], Tensor[(1, 8, 28, 28), float32]) */;
  %70 = %68.1 /* ty=Tensor[(1, 28, 28, 28), float32] */;
  %71 = fn (%FunctionVar_5_0: Tensor[(1, 28, 28, 28), float32] /* ty=Tensor[(1, 28, 28, 28), float32] */, PartitionedFromPattern="nn.conv2d_nn.bias_add_", Composite="imcflow.conv2d-bias_add") -> Tensor[(1, 64, 28, 28), float32] {
    %69 = nn.conv2d(%FunctionVar_5_0, meta[relay.Constant][34] /* ty=Tensor[(64, 28, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_1:0:0 */;
    nn.bias_add(%69, meta[relay.Constant][35] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_1:0:0 */
  } /* ty=fn (Tensor[(1, 28, 28, 28), float32]) -> Tensor[(1, 64, 28, 28), float32] */;
  %74 = %68.2 /* ty=Tensor[(1, 8, 28, 28), float32] */;
  %75 = fn (%FunctionVar_3_02: Tensor[(1, 8, 28, 28), float32] /* ty=Tensor[(1, 8, 28, 28), float32] */, PartitionedFromPattern="nn.conv2d_nn.bias_add_divide_", Composite="imcflow.conv2d-bias_add-div") -> Tensor[(1, 64, 28, 28), float32] {
    %72 = nn.conv2d(%FunctionVar_3_02, meta[relay.Constant][36] /* ty=Tensor[(64, 8, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_2:0:0 */;
    %73 = nn.bias_add(%72, meta[relay.Constant][37] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_2:0:0 */;
    divide(%73, 2f /* ty=float32 span=aten::div_1:0:0 */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::div_1:0:0 */
  } /* ty=fn (Tensor[(1, 8, 28, 28), float32]) -> Tensor[(1, 64, 28, 28), float32] */;
  %76 = %68.0 /* ty=Tensor[(1, 28, 28, 28), float32] */;
  %77 = %71(%70) /* ty=Tensor[(1, 64, 28, 28), float32] */;
  %78 = %75(%74) /* ty=Tensor[(1, 64, 28, 28), float32] */;
  %79 = fn (%FunctionVar_3_01: Tensor[(1, 28, 28, 28), float32] /* ty=Tensor[(1, 28, 28, 28), float32] */, %FunctionVar_3_1: Tensor[(1, 64, 28, 28), float32] /* ty=Tensor[(1, 64, 28, 28), float32] */, %FunctionVar_3_2: Tensor[(1, 64, 28, 28), float32] /* ty=Tensor[(1, 64, 28, 28), float32] */, PartitionedFromPattern="nn.conv2d_nn.bias_add_add_divide_add_nn.batch_norm_TupleGetItem0_nn.relu_qnn.imcflow_min_max_quantize_", Composite="imcflow.conv2d-bias_add-add-div-add-bn-relu-min_max_quant") -> Tensor[(1, 64, 28, 28), float32] {
    %60 = nn.conv2d(%FunctionVar_3_01, meta[relay.Constant][28] /* ty=Tensor[(64, 28, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_0:0:0 */;
    %61 = nn.bias_add(%60, meta[relay.Constant][29] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_0:0:0 */;
    %62 = add(%61, %FunctionVar_3_1) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::add_0:0:0 */;
    %63 = divide(%62, 2f /* ty=float32 span=aten::div_0:0:0 */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::div_0:0:0 */;
    %64 = add(%63, %FunctionVar_3_2) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::add_1:0:0 */;
    %65 = nn.batch_norm(%64, meta[relay.Constant][30] /* ty=Tensor[(64), float32] */, meta[relay.Constant][31] /* ty=Tensor[(64), float32] */, meta[relay.Constant][32] /* ty=Tensor[(64), float32] */, meta[relay.Constant][33] /* ty=Tensor[(64), float32] */) /* ty=(Tensor[(1, 64, 28, 28), float32], Tensor[(64), float32], Tensor[(64), float32]) span=aten::batch_norm_0:0:0 */;
    %66 = %65.0 /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::batch_norm_0:0:0 */;
    %67 = nn.relu(%66) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::relu_0:0:0 */;
    qnn.imcflow_min_max_quantize(%67, 0f /* ty=float32 span=imcflow::min_max_quant_0:0:0 */, 1f /* ty=float32 span=imcflow::min_max_quant_0:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 64, 28, 28), float32] span=imcflow::min_max_quant_0:0:0 */
  } /* ty=fn (Tensor[(1, 28, 28, 28), float32], Tensor[(1, 64, 28, 28), float32], Tensor[(1, 64, 28, 28), float32]) -> Tensor[(1, 64, 28, 28), float32] */;
  %89 = fn (%FunctionVar_4_0: Tensor[(1, 28, 28, 28), float32] /* ty=Tensor[(1, 28, 28, 28), float32] */, PartitionedFromPattern="nn.conv2d_nn.bias_add_", Composite="imcflow.conv2d-bias_add") -> Tensor[(1, 64, 28, 28), float32] {
    %88 = nn.conv2d(%FunctionVar_4_0, meta[relay.Constant][44] /* ty=Tensor[(64, 28, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_4:0:0 */;
    nn.bias_add(%88, meta[relay.Constant][45] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_4:0:0 */
  } /* ty=fn (Tensor[(1, 28, 28, 28), float32]) -> Tensor[(1, 64, 28, 28), float32] */;
  %92 = fn (%FunctionVar_2_02: Tensor[(1, 8, 28, 28), float32] /* ty=Tensor[(1, 8, 28, 28), float32] */, PartitionedFromPattern="nn.conv2d_nn.bias_add_divide_", Composite="imcflow.conv2d-bias_add-div") -> Tensor[(1, 64, 28, 28), float32] {
    %90 = nn.conv2d(%FunctionVar_2_02, meta[relay.Constant][46] /* ty=Tensor[(64, 8, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_5:0:0 */;
    %91 = nn.bias_add(%90, meta[relay.Constant][47] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_5:0:0 */;
    divide(%91, 2f /* ty=float32 span=aten::div_3:0:0 */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::div_3:0:0 */
  } /* ty=fn (Tensor[(1, 8, 28, 28), float32]) -> Tensor[(1, 64, 28, 28), float32] */;
  %93 = %89(%70) /* ty=Tensor[(1, 64, 28, 28), float32] */;
  %94 = %92(%74) /* ty=Tensor[(1, 64, 28, 28), float32] */;
  %95 = fn (%FunctionVar_2_01: Tensor[(1, 28, 28, 28), float32] /* ty=Tensor[(1, 28, 28, 28), float32] */, %FunctionVar_2_1: Tensor[(1, 64, 28, 28), float32] /* ty=Tensor[(1, 64, 28, 28), float32] */, %FunctionVar_2_2: Tensor[(1, 64, 28, 28), float32] /* ty=Tensor[(1, 64, 28, 28), float32] */, PartitionedFromPattern="nn.conv2d_nn.bias_add_add_divide_add_nn.batch_norm_TupleGetItem0_nn.relu_qnn.imcflow_min_max_quantize_", Composite="imcflow.conv2d-bias_add-add-div-add-bn-relu-min_max_quant") -> Tensor[(1, 64, 28, 28), float32] {
    %80 = nn.conv2d(%FunctionVar_2_01, meta[relay.Constant][38] /* ty=Tensor[(64, 28, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_3:0:0 */;
    %81 = nn.bias_add(%80, meta[relay.Constant][39] /* ty=Tensor[(64), float32] */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::_convolution_3:0:0 */;
    %82 = add(%81, %FunctionVar_2_1) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::add_2:0:0 */;
    %83 = divide(%82, 2f /* ty=float32 span=aten::div_2:0:0 */) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::div_2:0:0 */;
    %84 = add(%83, %FunctionVar_2_2) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::add_3:0:0 */;
    %85 = nn.batch_norm(%84, meta[relay.Constant][40] /* ty=Tensor[(64), float32] */, meta[relay.Constant][41] /* ty=Tensor[(64), float32] */, meta[relay.Constant][42] /* ty=Tensor[(64), float32] */, meta[relay.Constant][43] /* ty=Tensor[(64), float32] */) /* ty=(Tensor[(1, 64, 28, 28), float32], Tensor[(64), float32], Tensor[(64), float32]) span=aten::batch_norm_1:0:0 */;
    %86 = %85.0 /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::batch_norm_1:0:0 */;
    %87 = nn.relu(%86) /* ty=Tensor[(1, 64, 28, 28), float32] span=aten::relu_1:0:0 */;
    qnn.imcflow_min_max_quantize(%87, 0f /* ty=float32 span=imcflow::min_max_quant_1:0:0 */, 1f /* ty=float32 span=imcflow::min_max_quant_1:0:0 */, out_dtype="float32", axis=1) /* ty=Tensor[(1, 64, 28, 28), float32] span=imcflow::min_max_quant_1:0:0 */
  } /* ty=fn (Tensor[(1, 28, 28, 28), float32], Tensor[(1, 64, 28, 28), float32], Tensor[(1, 64, 28, 28), float32]) -> Tensor[(1, 64, 28, 28), float32] */;
  %96 = %79(%76, %77, %78) /* ty=Tensor[(1, 64, 28, 28), float32] */;
  %97 = %95(%76, %93, %94) /* ty=Tensor[(1, 64, 28, 28), float32] */;
  %98 = (%96, %97) /* ty=(Tensor[(1, 64, 28, 28), float32], Tensor[(1, 64, 28, 28), float32]) */;
  concatenate(%98, axis=1) /* ty=Tensor[(1, 128, 28, 28), float32] */
}

