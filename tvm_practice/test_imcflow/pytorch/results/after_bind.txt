type List[A] {
  Cons(A, List[A]),
  Nil,
}

type Option[A] {
  Some(A),
  None,
}

type Tree[A] {
  Rose(A, List[Tree[A]]),
}

type tensor_float16_t {
  tensor_nil_float16,
  tensor0_float16(float16),
  tensor1_float16(Tensor[(?), float16]),
  tensor2_float16(Tensor[(?, ?), float16]),
  tensor3_float16(Tensor[(?, ?, ?), float16]),
  tensor4_float16(Tensor[(?, ?, ?, ?), float16]),
  tensor5_float16(Tensor[(?, ?, ?, ?, ?), float16]),
  tensor6_float16(Tensor[(?, ?, ?, ?, ?, ?), float16]),
}

type tensor_float32_t {
  tensor_nil_float32,
  tensor0_float32(float32),
  tensor1_float32(Tensor[(?), float32]),
  tensor2_float32(Tensor[(?, ?), float32]),
  tensor3_float32(Tensor[(?, ?, ?), float32]),
  tensor4_float32(Tensor[(?, ?, ?, ?), float32]),
  tensor5_float32(Tensor[(?, ?, ?, ?, ?), float32]),
  tensor6_float32(Tensor[(?, ?, ?, ?, ?, ?), float32]),
}

type tensor_float64_t {
  tensor_nil_float64,
  tensor0_float64(float64),
  tensor1_float64(Tensor[(?), float64]),
  tensor2_float64(Tensor[(?, ?), float64]),
  tensor3_float64(Tensor[(?, ?, ?), float64]),
  tensor4_float64(Tensor[(?, ?, ?, ?), float64]),
  tensor5_float64(Tensor[(?, ?, ?, ?, ?), float64]),
  tensor6_float64(Tensor[(?, ?, ?, ?, ?, ?), float64]),
}

type tensor_int16_t {
  tensor_nil_int16,
  tensor0_int16(int16),
  tensor1_int16(Tensor[(?), int16]),
  tensor2_int16(Tensor[(?, ?), int16]),
  tensor3_int16(Tensor[(?, ?, ?), int16]),
  tensor4_int16(Tensor[(?, ?, ?, ?), int16]),
  tensor5_int16(Tensor[(?, ?, ?, ?, ?), int16]),
  tensor6_int16(Tensor[(?, ?, ?, ?, ?, ?), int16]),
}

type tensor_int32_t {
  tensor_nil_int32,
  tensor0_int32(int32),
  tensor1_int32(Tensor[(?), int32]),
  tensor2_int32(Tensor[(?, ?), int32]),
  tensor3_int32(Tensor[(?, ?, ?), int32]),
  tensor4_int32(Tensor[(?, ?, ?, ?), int32]),
  tensor5_int32(Tensor[(?, ?, ?, ?, ?), int32]),
  tensor6_int32(Tensor[(?, ?, ?, ?, ?, ?), int32]),
}

type tensor_int64_t {
  tensor_nil_int64,
  tensor0_int64(int64),
  tensor1_int64(Tensor[(?), int64]),
  tensor2_int64(Tensor[(?, ?), int64]),
  tensor3_int64(Tensor[(?, ?, ?), int64]),
  tensor4_int64(Tensor[(?, ?, ?, ?), int64]),
  tensor5_int64(Tensor[(?, ?, ?, ?, ?), int64]),
  tensor6_int64(Tensor[(?, ?, ?, ?, ?, ?), int64]),
}

type tensor_int8_t {
  tensor_nil_int8,
  tensor0_int8(int8),
  tensor1_int8(Tensor[(?), int8]),
  tensor2_int8(Tensor[(?, ?), int8]),
  tensor3_int8(Tensor[(?, ?, ?), int8]),
  tensor4_int8(Tensor[(?, ?, ?, ?), int8]),
  tensor5_int8(Tensor[(?, ?, ?, ?, ?), int8]),
  tensor6_int8(Tensor[(?, ?, ?, ?, ?, ?), int8]),
}

type tensor_uint16_t {
  tensor_nil_uint16,
  tensor0_uint16(uint16),
  tensor1_uint16(Tensor[(?), uint16]),
  tensor2_uint16(Tensor[(?, ?), uint16]),
  tensor3_uint16(Tensor[(?, ?, ?), uint16]),
  tensor4_uint16(Tensor[(?, ?, ?, ?), uint16]),
  tensor5_uint16(Tensor[(?, ?, ?, ?, ?), uint16]),
  tensor6_uint16(Tensor[(?, ?, ?, ?, ?, ?), uint16]),
}

type tensor_uint8_t {
  tensor_nil_uint8,
  tensor0_uint8(uint8),
  tensor1_uint8(Tensor[(?), uint8]),
  tensor2_uint8(Tensor[(?, ?), uint8]),
  tensor3_uint8(Tensor[(?, ?, ?), uint8]),
  tensor4_uint8(Tensor[(?, ?, ?, ?), uint8]),
  tensor5_uint8(Tensor[(?, ?, ?, ?, ?), uint8]),
  tensor6_uint8(Tensor[(?, ?, ?, ?, ?, ?), uint8]),
}

def @main(%input0: Tensor[(1, 64, 28, 28), float32] /* span=aten::split_with_sizes_0.input0:0:0 */) {
  %0 = split(%input0, indices_or_sections=[meta[runtime.BoxInt][0], meta[runtime.BoxInt][1]], axis=1) /* span=aten::split_with_sizes_0:0:0 */;
  %1 = %0.0 /* span=aten::split_with_sizes_0:0:0 */;
  %2 = nn.conv2d(%1, meta[relay.Constant][0], padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_0:0:0 */;
  %3 = %0.1 /* span=aten::split_with_sizes_0:0:0 */;
  %4 = nn.conv2d(%3, meta[relay.Constant][2], padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_1:0:0 */;
  %5 = nn.bias_add(%2, meta[relay.Constant][1]) /* span=aten::_convolution_0:0:0 */;
  %6 = nn.bias_add(%4, meta[relay.Constant][3]) /* span=aten::_convolution_1:0:0 */;
  %7 = add(%5, %6) /* span=aten::add_0:0:0 */;
  %8 = %0.2 /* span=aten::split_with_sizes_0:0:0 */;
  %9 = nn.conv2d(%8, meta[relay.Constant][4], padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_2:0:0 */;
  %10 = nn.bias_add(%9, meta[relay.Constant][5]) /* span=aten::_convolution_2:0:0 */;
  %11 = divide(%7, 2f /* span=aten::div_0:0:0 */) /* span=aten::div_0:0:0 */;
  %12 = divide(%10, 2f /* span=aten::div_1:0:0 */) /* span=aten::div_1:0:0 */;
  %13 = add(%11, %12) /* span=aten::add_1:0:0 */;
  %14 = nn.batch_norm(%13, meta[relay.Constant][6], meta[relay.Constant][7], meta[relay.Constant][8], meta[relay.Constant][9]) /* span=aten::batch_norm_0:0:0 */;
  %15 = %14.0 /* span=aten::batch_norm_0:0:0 */;
  %16 = nn.relu(%15) /* span=aten::relu_0:0:0 */;
  %17 = nn.conv2d(%1, meta[relay.Constant][10], padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_3:0:0 */;
  %18 = nn.conv2d(%3, meta[relay.Constant][12], padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_4:0:0 */;
  %19 = nn.bias_add(%17, meta[relay.Constant][11]) /* span=aten::_convolution_3:0:0 */;
  %20 = nn.bias_add(%18, meta[relay.Constant][13]) /* span=aten::_convolution_4:0:0 */;
  %21 = add(%19, %20) /* span=aten::add_2:0:0 */;
  %22 = nn.conv2d(%8, meta[relay.Constant][14], padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_5:0:0 */;
  %23 = nn.bias_add(%22, meta[relay.Constant][15]) /* span=aten::_convolution_5:0:0 */;
  %24 = divide(%21, 2f /* span=aten::div_2:0:0 */) /* span=aten::div_2:0:0 */;
  %25 = divide(%23, 2f /* span=aten::div_3:0:0 */) /* span=aten::div_3:0:0 */;
  %26 = add(%24, %25) /* span=aten::add_3:0:0 */;
  %27 = nn.batch_norm(%26, meta[relay.Constant][16], meta[relay.Constant][17], meta[relay.Constant][18], meta[relay.Constant][19]) /* span=aten::batch_norm_1:0:0 */;
  %28 = %27.0 /* span=aten::batch_norm_1:0:0 */;
  %29 = nn.relu(%28) /* span=aten::relu_1:0:0 */;
  %30 = qnn.imcflow_min_max_quantize(%16, 0f /* span=imcflow::min_max_quant_0:0:0 */, 1f /* span=imcflow::min_max_quant_0:0:0 */, out_dtype="float32", axis=1) /* span=imcflow::min_max_quant_0:0:0 */;
  %31 = qnn.imcflow_min_max_quantize(%29, 0f /* span=imcflow::min_max_quant_1:0:0 */, 1f /* span=imcflow::min_max_quant_1:0:0 */, out_dtype="float32", axis=1) /* span=imcflow::min_max_quant_1:0:0 */;
  %32 = (%30, %31) /* span=aten::cat_0:0:0 */;
  %33 = concatenate(%32, axis=1) /* span=aten::cat_0:0:0 */;
  %34 = split(%33, indices_or_sections=[meta[runtime.BoxInt][2], meta[runtime.BoxInt][3], meta[runtime.BoxInt][4], meta[runtime.BoxInt][5]], axis=1) /* span=aten::split_with_sizes_1:0:0 */;
  %35 = %34.0 /* span=aten::split_with_sizes_1:0:0 */;
  %36 = nn.conv2d(%35, meta[relay.Constant][20], padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_6:0:0 */;
  %37 = %34.1 /* span=aten::split_with_sizes_1:0:0 */;
  %38 = nn.conv2d(%37, meta[relay.Constant][22], padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_7:0:0 */;
  %39 = nn.bias_add(%36, meta[relay.Constant][21]) /* span=aten::_convolution_6:0:0 */;
  %40 = nn.bias_add(%38, meta[relay.Constant][23]) /* span=aten::_convolution_7:0:0 */;
  %41 = add(%39, %40) /* span=aten::add_4:0:0 */;
  %42 = %34.2 /* span=aten::split_with_sizes_1:0:0 */;
  %43 = nn.conv2d(%42, meta[relay.Constant][24], padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_8:0:0 */;
  %44 = %34.3 /* span=aten::split_with_sizes_1:0:0 */;
  %45 = nn.conv2d(%44, meta[relay.Constant][26], padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_9:0:0 */;
  %46 = nn.bias_add(%43, meta[relay.Constant][25]) /* span=aten::_convolution_8:0:0 */;
  %47 = nn.bias_add(%45, meta[relay.Constant][27]) /* span=aten::_convolution_9:0:0 */;
  %48 = add(%46, %47) /* span=aten::add_5:0:0 */;
  %49 = divide(%41, 2f /* span=aten::div_4:0:0 */) /* span=aten::div_4:0:0 */;
  %50 = divide(%48, 2f /* span=aten::div_5:0:0 */) /* span=aten::div_5:0:0 */;
  %51 = %34.4 /* span=aten::split_with_sizes_1:0:0 */;
  %52 = nn.conv2d(%51, meta[relay.Constant][28], padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_10:0:0 */;
  %53 = nn.bias_add(%52, meta[relay.Constant][29]) /* span=aten::_convolution_10:0:0 */;
  %54 = add(%49, %50) /* span=aten::add_6:0:0 */;
  %55 = divide(%53, 2f /* span=aten::div_6:0:0 */) /* span=aten::div_6:0:0 */;
  %56 = add(%54, %55) /* span=aten::add_7:0:0 */;
  %57 = nn.batch_norm(%56, meta[relay.Constant][30], meta[relay.Constant][31], meta[relay.Constant][32], meta[relay.Constant][33]) /* span=aten::batch_norm_2:0:0 */;
  %58 = %57.0 /* span=aten::batch_norm_2:0:0 */;
  %59 = nn.relu(%58) /* span=aten::relu_2:0:0 */;
  %60 = nn.conv2d(%35, meta[relay.Constant][34], padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_11:0:0 */;
  %61 = nn.conv2d(%37, meta[relay.Constant][36], padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_12:0:0 */;
  %62 = nn.bias_add(%60, meta[relay.Constant][35]) /* span=aten::_convolution_11:0:0 */;
  %63 = nn.bias_add(%61, meta[relay.Constant][37]) /* span=aten::_convolution_12:0:0 */;
  %64 = add(%62, %63) /* span=aten::add_8:0:0 */;
  %65 = nn.conv2d(%42, meta[relay.Constant][38], padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_13:0:0 */;
  %66 = nn.conv2d(%44, meta[relay.Constant][40], padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_14:0:0 */;
  %67 = nn.bias_add(%65, meta[relay.Constant][39]) /* span=aten::_convolution_13:0:0 */;
  %68 = nn.bias_add(%66, meta[relay.Constant][41]) /* span=aten::_convolution_14:0:0 */;
  %69 = add(%67, %68) /* span=aten::add_9:0:0 */;
  %70 = divide(%64, 2f /* span=aten::div_7:0:0 */) /* span=aten::div_7:0:0 */;
  %71 = divide(%69, 2f /* span=aten::div_8:0:0 */) /* span=aten::div_8:0:0 */;
  %72 = nn.conv2d(%51, meta[relay.Constant][42], padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_15:0:0 */;
  %73 = nn.bias_add(%72, meta[relay.Constant][43]) /* span=aten::_convolution_15:0:0 */;
  %74 = add(%70, %71) /* span=aten::add_10:0:0 */;
  %75 = divide(%73, 2f /* span=aten::div_9:0:0 */) /* span=aten::div_9:0:0 */;
  %76 = add(%74, %75) /* span=aten::add_11:0:0 */;
  %77 = nn.batch_norm(%76, meta[relay.Constant][44], meta[relay.Constant][45], meta[relay.Constant][46], meta[relay.Constant][47]) /* span=aten::batch_norm_3:0:0 */;
  %78 = %77.0 /* span=aten::batch_norm_3:0:0 */;
  %79 = nn.relu(%78) /* span=aten::relu_3:0:0 */;
  %80 = qnn.imcflow_min_max_quantize(%59, 0f /* span=imcflow::min_max_quant_2:0:0 */, 1f /* span=imcflow::min_max_quant_2:0:0 */, out_dtype="float32", axis=1) /* span=imcflow::min_max_quant_2:0:0 */;
  %81 = qnn.imcflow_min_max_quantize(%79, 0f /* span=imcflow::min_max_quant_3:0:0 */, 1f /* span=imcflow::min_max_quant_3:0:0 */, out_dtype="float32", axis=1) /* span=imcflow::min_max_quant_3:0:0 */;
  %82 = (%80, %81) /* span=aten::cat_1:0:0 */;
  concatenate(%82, axis=1) /* span=aten::cat_1:0:0 */
}

