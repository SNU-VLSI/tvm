type List[A] {
  Cons(A, List[A]),
  Nil,
}

type Option[A] {
  Some(A),
  None,
}

type Tree[A] {
  Rose(A, List[Tree[A]]),
}

type tensor_float16_t {
  tensor_nil_float16,
  tensor0_float16(float16),
  tensor1_float16(Tensor[(?), float16]),
  tensor2_float16(Tensor[(?, ?), float16]),
  tensor3_float16(Tensor[(?, ?, ?), float16]),
  tensor4_float16(Tensor[(?, ?, ?, ?), float16]),
  tensor5_float16(Tensor[(?, ?, ?, ?, ?), float16]),
  tensor6_float16(Tensor[(?, ?, ?, ?, ?, ?), float16]),
}

type tensor_float32_t {
  tensor_nil_float32,
  tensor0_float32(float32),
  tensor1_float32(Tensor[(?), float32]),
  tensor2_float32(Tensor[(?, ?), float32]),
  tensor3_float32(Tensor[(?, ?, ?), float32]),
  tensor4_float32(Tensor[(?, ?, ?, ?), float32]),
  tensor5_float32(Tensor[(?, ?, ?, ?, ?), float32]),
  tensor6_float32(Tensor[(?, ?, ?, ?, ?, ?), float32]),
}

type tensor_float64_t {
  tensor_nil_float64,
  tensor0_float64(float64),
  tensor1_float64(Tensor[(?), float64]),
  tensor2_float64(Tensor[(?, ?), float64]),
  tensor3_float64(Tensor[(?, ?, ?), float64]),
  tensor4_float64(Tensor[(?, ?, ?, ?), float64]),
  tensor5_float64(Tensor[(?, ?, ?, ?, ?), float64]),
  tensor6_float64(Tensor[(?, ?, ?, ?, ?, ?), float64]),
}

type tensor_int16_t {
  tensor_nil_int16,
  tensor0_int16(int16),
  tensor1_int16(Tensor[(?), int16]),
  tensor2_int16(Tensor[(?, ?), int16]),
  tensor3_int16(Tensor[(?, ?, ?), int16]),
  tensor4_int16(Tensor[(?, ?, ?, ?), int16]),
  tensor5_int16(Tensor[(?, ?, ?, ?, ?), int16]),
  tensor6_int16(Tensor[(?, ?, ?, ?, ?, ?), int16]),
}

type tensor_int32_t {
  tensor_nil_int32,
  tensor0_int32(int32),
  tensor1_int32(Tensor[(?), int32]),
  tensor2_int32(Tensor[(?, ?), int32]),
  tensor3_int32(Tensor[(?, ?, ?), int32]),
  tensor4_int32(Tensor[(?, ?, ?, ?), int32]),
  tensor5_int32(Tensor[(?, ?, ?, ?, ?), int32]),
  tensor6_int32(Tensor[(?, ?, ?, ?, ?, ?), int32]),
}

type tensor_int64_t {
  tensor_nil_int64,
  tensor0_int64(int64),
  tensor1_int64(Tensor[(?), int64]),
  tensor2_int64(Tensor[(?, ?), int64]),
  tensor3_int64(Tensor[(?, ?, ?), int64]),
  tensor4_int64(Tensor[(?, ?, ?, ?), int64]),
  tensor5_int64(Tensor[(?, ?, ?, ?, ?), int64]),
  tensor6_int64(Tensor[(?, ?, ?, ?, ?, ?), int64]),
}

type tensor_int8_t {
  tensor_nil_int8,
  tensor0_int8(int8),
  tensor1_int8(Tensor[(?), int8]),
  tensor2_int8(Tensor[(?, ?), int8]),
  tensor3_int8(Tensor[(?, ?, ?), int8]),
  tensor4_int8(Tensor[(?, ?, ?, ?), int8]),
  tensor5_int8(Tensor[(?, ?, ?, ?, ?), int8]),
  tensor6_int8(Tensor[(?, ?, ?, ?, ?, ?), int8]),
}

type tensor_uint16_t {
  tensor_nil_uint16,
  tensor0_uint16(uint16),
  tensor1_uint16(Tensor[(?), uint16]),
  tensor2_uint16(Tensor[(?, ?), uint16]),
  tensor3_uint16(Tensor[(?, ?, ?), uint16]),
  tensor4_uint16(Tensor[(?, ?, ?, ?), uint16]),
  tensor5_uint16(Tensor[(?, ?, ?, ?, ?), uint16]),
  tensor6_uint16(Tensor[(?, ?, ?, ?, ?, ?), uint16]),
}

type tensor_uint8_t {
  tensor_nil_uint8,
  tensor0_uint8(uint8),
  tensor1_uint8(Tensor[(?), uint8]),
  tensor2_uint8(Tensor[(?, ?), uint8]),
  tensor3_uint8(Tensor[(?, ?, ?), uint8]),
  tensor4_uint8(Tensor[(?, ?, ?, ?), uint8]),
  tensor5_uint8(Tensor[(?, ?, ?, ?, ?), uint8]),
  tensor6_uint8(Tensor[(?, ?, ?, ?, ?, ?), uint8]),
}

def @main(%input0: Tensor[(1, 64, 28, 28), float32] /* span=aten::split_with_sizes_0.input0:0:0 */, %aten::_convolution_0.weight: Tensor[(64, 28, 3, 3), float32] /* span=aten::_convolution_0.weight:0:0 */, %aten::_convolution_0.bias: Tensor[(64), float32] /* span=aten::_convolution_0.bias:0:0 */, %aten::_convolution_1.weight: Tensor[(64, 28, 3, 3), float32] /* span=aten::_convolution_1.weight:0:0 */, %aten::_convolution_1.bias: Tensor[(64), float32] /* span=aten::_convolution_1.bias:0:0 */, %aten::_convolution_2.weight: Tensor[(64, 8, 3, 3), float32] /* span=aten::_convolution_2.weight:0:0 */, %aten::_convolution_2.bias: Tensor[(64), float32] /* span=aten::_convolution_2.bias:0:0 */, %aten::batch_norm_0.weight: Tensor[(64), float32] /* span=aten::batch_norm_0.weight:0:0 */, %aten::batch_norm_0.bias: Tensor[(64), float32] /* span=aten::batch_norm_0.bias:0:0 */, %aten::batch_norm_0.running_mean: Tensor[(64), float32] /* span=aten::batch_norm_0.running_mean:0:0 */, %aten::batch_norm_0.running_var: Tensor[(64), float32] /* span=aten::batch_norm_0.running_var:0:0 */, %aten::_convolution_3.weight: Tensor[(64, 28, 3, 3), float32] /* span=aten::_convolution_3.weight:0:0 */, %aten::_convolution_3.bias: Tensor[(64), float32] /* span=aten::_convolution_3.bias:0:0 */, %aten::_convolution_4.weight: Tensor[(64, 28, 3, 3), float32] /* span=aten::_convolution_4.weight:0:0 */, %aten::_convolution_4.bias: Tensor[(64), float32] /* span=aten::_convolution_4.bias:0:0 */, %aten::_convolution_5.weight: Tensor[(64, 8, 3, 3), float32] /* span=aten::_convolution_5.weight:0:0 */, %aten::_convolution_5.bias: Tensor[(64), float32] /* span=aten::_convolution_5.bias:0:0 */, %aten::batch_norm_1.weight: Tensor[(64), float32] /* span=aten::batch_norm_1.weight:0:0 */, %aten::batch_norm_1.bias: Tensor[(64), float32] /* span=aten::batch_norm_1.bias:0:0 */, %aten::batch_norm_1.running_mean: Tensor[(64), float32] /* span=aten::batch_norm_1.running_mean:0:0 */, %aten::batch_norm_1.running_var: Tensor[(64), float32] /* span=aten::batch_norm_1.running_var:0:0 */) {
  %0 = split(%input0, indices_or_sections=[meta[runtime.BoxInt][0], meta[runtime.BoxInt][1]], axis=1) /* span=aten::split_with_sizes_0:0:0 */;
  %1 = %0.0 /* span=aten::split_with_sizes_0:0:0 */;
  %2 = nn.conv2d(%1, %aten::_convolution_0.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_0:0:0 */;
  %3 = %0.1 /* span=aten::split_with_sizes_0:0:0 */;
  %4 = nn.conv2d(%3, %aten::_convolution_1.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_1:0:0 */;
  %5 = nn.bias_add(%2, %aten::_convolution_0.bias) /* span=aten::_convolution_0:0:0 */;
  %6 = nn.bias_add(%4, %aten::_convolution_1.bias) /* span=aten::_convolution_1:0:0 */;
  %7 = add(%5, %6) /* span=aten::add_0:0:0 */;
  %8 = %0.2 /* span=aten::split_with_sizes_0:0:0 */;
  %9 = nn.conv2d(%8, %aten::_convolution_2.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_2:0:0 */;
  %10 = nn.bias_add(%9, %aten::_convolution_2.bias) /* span=aten::_convolution_2:0:0 */;
  %11 = divide(%7, 2f /* span=aten::div_0:0:0 */) /* span=aten::div_0:0:0 */;
  %12 = divide(%10, 2f /* span=aten::div_1:0:0 */) /* span=aten::div_1:0:0 */;
  %13 = add(%11, %12) /* span=aten::add_1:0:0 */;
  %14 = nn.batch_norm(%13, %aten::batch_norm_0.weight, %aten::batch_norm_0.bias, %aten::batch_norm_0.running_mean, %aten::batch_norm_0.running_var) /* span=aten::batch_norm_0:0:0 */;
  %15 = %14.0 /* span=aten::batch_norm_0:0:0 */;
  %16 = nn.relu(%15) /* span=aten::relu_0:0:0 */;
  %17 = nn.conv2d(%1, %aten::_convolution_3.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_3:0:0 */;
  %18 = nn.conv2d(%3, %aten::_convolution_4.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_4:0:0 */;
  %19 = nn.bias_add(%17, %aten::_convolution_3.bias) /* span=aten::_convolution_3:0:0 */;
  %20 = nn.bias_add(%18, %aten::_convolution_4.bias) /* span=aten::_convolution_4:0:0 */;
  %21 = add(%19, %20) /* span=aten::add_2:0:0 */;
  %22 = nn.conv2d(%8, %aten::_convolution_5.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* span=aten::_convolution_5:0:0 */;
  %23 = nn.bias_add(%22, %aten::_convolution_5.bias) /* span=aten::_convolution_5:0:0 */;
  %24 = divide(%21, 2f /* span=aten::div_2:0:0 */) /* span=aten::div_2:0:0 */;
  %25 = divide(%23, 2f /* span=aten::div_3:0:0 */) /* span=aten::div_3:0:0 */;
  %26 = add(%24, %25) /* span=aten::add_3:0:0 */;
  %27 = nn.batch_norm(%26, %aten::batch_norm_1.weight, %aten::batch_norm_1.bias, %aten::batch_norm_1.running_mean, %aten::batch_norm_1.running_var) /* span=aten::batch_norm_1:0:0 */;
  %28 = %27.0 /* span=aten::batch_norm_1:0:0 */;
  %29 = nn.relu(%28) /* span=aten::relu_1:0:0 */;
  %30 = qnn.imcflow_min_max_quantize(%16, 0f /* span=imcflow::min_max_quant_0:0:0 */, 1f /* span=imcflow::min_max_quant_0:0:0 */, out_dtype="float32", axis=1) /* span=imcflow::min_max_quant_0:0:0 */;
  %31 = qnn.imcflow_min_max_quantize(%29, 0f /* span=imcflow::min_max_quant_1:0:0 */, 1f /* span=imcflow::min_max_quant_1:0:0 */, out_dtype="float32", axis=1) /* span=imcflow::min_max_quant_1:0:0 */;
  %32 = (%30, %31) /* span=aten::cat_0:0:0 */;
  concatenate(%32) /* span=aten::cat_0:0:0 */
}

