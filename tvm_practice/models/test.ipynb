{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-05 01:35:06.895619: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-05 01:35:06.898703: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-05 01:35:06.936747: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-05 01:35:06.936768: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-05 01:35:06.938171: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-05 01:35:06.945434: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-05 01:35:06.946093: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-05 01:35:07.683483: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm import te\n",
    "import tvm.relay as relay\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d():\n",
    "  input_shape = [32, 32, 3]\n",
    "  inputs = Input(shape=input_shape)\n",
    "  outputs = Conv2D(filters=16, kernel_size=3, strides=1, padding='same')(inputs)\n",
    "  model = Model(inputs=inputs, outputs=outputs)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod, params = relay.frontend.from_keras(conv2d(), shape={'input_1': (1, 3, 32, 32)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "graph_module = relay.build(mod, params=params, target=\"llvm -mtriple=aarch64-linux-gnu\")\n",
    "# graph_module = relay.build(mod, params=params, target=\"c\")\n",
    "# print(graph_module.get_graph_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// tvm target: c -keys=cpu \n",
      "#define TVM_EXPORTS\n",
      "#include \"tvm/runtime/c_runtime_api.h\"\n",
      "#include \"tvm/runtime/c_backend_api.h\"\n",
      "#include <math.h>\n",
      "#include <stdbool.h>\n",
      "#ifdef __cplusplus\n",
      "extern \"C\"\n",
      "#endif\n",
      "TVM_DLL int32_t tvmgen_default_fused_nn_conv2d_nn_bias_add(void* args, int32_t* arg_type_ids, int32_t num_args, void* out_ret_value, int32_t* out_ret_tcode, void* resource_handle);\n",
      "#ifdef __cplusplus\n",
      "extern \"C\"\n",
      "#endif\n",
      "TVM_DLL int32_t tvmgen_default_fused_nn_conv2d_nn_bias_add(void* args, int32_t* arg_type_ids, int32_t num_args, void* out_ret_value, int32_t* out_ret_tcode, void* resource_handle) {\n",
      "  int32_t p0_code = arg_type_ids[0];\n",
      "  int32_t p1_code = arg_type_ids[1];\n",
      "  int32_t p2_code = arg_type_ids[2];\n",
      "  int32_t T_add_code = arg_type_ids[3];\n",
      "  void* p0 = (((TVMValue*)args)[0].v_handle);\n",
      "  void* p1 = (((TVMValue*)args)[1].v_handle);\n",
      "  void* p2 = (((TVMValue*)args)[2].v_handle);\n",
      "  void* T_add = (((TVMValue*)args)[3].v_handle);\n",
      "  void* tvmgen_default_fused_nn_conv2d_nn_bias_add_p0_shape = (((DLTensor*)p0)[0].shape);\n",
      "  void* tvmgen_default_fused_nn_conv2d_nn_bias_add_p0_strides = (((DLTensor*)p0)[0].strides);\n",
      "  int32_t dev_id = (((DLTensor*)p0)[0].device.device_id);\n",
      "  void* p0_1 = (((DLTensor*)p0)[0].data);\n",
      "  void* tvmgen_default_fused_nn_conv2d_nn_bias_add_p1_shape = (((DLTensor*)p1)[0].shape);\n",
      "  void* tvmgen_default_fused_nn_conv2d_nn_bias_add_p1_strides = (((DLTensor*)p1)[0].strides);\n",
      "  void* p1_1 = (((DLTensor*)p1)[0].data);\n",
      "  void* tvmgen_default_fused_nn_conv2d_nn_bias_add_p2_shape = (((DLTensor*)p2)[0].shape);\n",
      "  void* tvmgen_default_fused_nn_conv2d_nn_bias_add_p2_strides = (((DLTensor*)p2)[0].strides);\n",
      "  void* p2_1 = (((DLTensor*)p2)[0].data);\n",
      "  void* tvmgen_default_fused_nn_conv2d_nn_bias_add_T_add_shape = (((DLTensor*)T_add)[0].shape);\n",
      "  void* tvmgen_default_fused_nn_conv2d_nn_bias_add_T_add_strides = (((DLTensor*)T_add)[0].strides);\n",
      "  void* T_add_1 = (((DLTensor*)T_add)[0].data);\n",
      "  if (!(tvmgen_default_fused_nn_conv2d_nn_bias_add_p0_strides == NULL)) {\n",
      "  }\n",
      "  if (!(tvmgen_default_fused_nn_conv2d_nn_bias_add_p1_strides == NULL)) {\n",
      "  }\n",
      "  if (!(tvmgen_default_fused_nn_conv2d_nn_bias_add_p2_strides == NULL)) {\n",
      "  }\n",
      "  if (!(tvmgen_default_fused_nn_conv2d_nn_bias_add_T_add_strides == NULL)) {\n",
      "  }\n",
      "  void* data_vec = TVMBackendAllocWorkspace(1, dev_id, (uint64_t)12288, 2, 32);\n",
      "  if (data_vec == NULL) {\n",
      "    return -1;\n",
      "  }\n",
      "  void* data_pad = TVMBackendAllocWorkspace(1, dev_id, (uint64_t)13872, 2, 32);\n",
      "  if (data_pad == NULL) {\n",
      "    return -1;\n",
      "  }\n",
      "  for (int32_t bs_c_fused_h_fused = 0; bs_c_fused_h_fused < 32; ++bs_c_fused_h_fused) {\n",
      "    for (int32_t w = 0; w < 32; ++w) {\n",
      "      for (int32_t vc = 0; vc < 3; ++vc) {\n",
      "        ((float*)data_vec)[(((bs_c_fused_h_fused * 96) + (w * 3)) + vc)] = ((float*)p0_1)[(((vc * 1024) + (bs_c_fused_h_fused * 32)) + w)];\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  for (int32_t i0_i1_fused_i2_fused = 0; i0_i1_fused_i2_fused < 34; ++i0_i1_fused_i2_fused) {\n",
      "    for (int32_t i3 = 0; i3 < 34; ++i3) {\n",
      "      int32_t cse_var_1 = (i3 * 3);\n",
      "      float3 condval;\n",
      "      if (((((1 <= i0_i1_fused_i2_fused) && (i0_i1_fused_i2_fused < 33)) && (1 <= i3)) && (i3 < 33))) {\n",
      "        int32_t3 v_ = int32_t3(((((i0_i1_fused_i2_fused * 96) + cse_var_1) - 99))+(1*0), ((((i0_i1_fused_i2_fused * 96) + cse_var_1) - 99))+(1*1), ((((i0_i1_fused_i2_fused * 96) + cse_var_1) - 99))+(1*2));\n",
      "        condval = (float3(((float*)data_vec)[v_.s0],((float*)data_vec)[v_.s1],((float*)data_vec)[v_.s2]));\n",
      "      } else {\n",
      "        condval = ((float3)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      }\n",
      "      *(float3*)(((float*)data_pad) + ((i0_i1_fused_i2_fused * 102) + cse_var_1)) = condval;\n",
      "    }\n",
      "  }\n",
      "  for (int32_t occ_k_h_fused = 0; occ_k_h_fused < 12; ++occ_k_h_fused) {\n",
      "    for (int32_t k_w = 0; k_w < 3; ++k_w) {\n",
      "      for (int32_t icb = 0; icb < 3; ++icb) {\n",
      "        int32_t4 v__1 = int32_t4(((((((occ_k_h_fused / 3) * 108) + (icb * 9)) + ((occ_k_h_fused % 3) * 3)) + k_w))+(27*0), ((((((occ_k_h_fused / 3) * 108) + (icb * 9)) + ((occ_k_h_fused % 3) * 3)) + k_w))+(27*1), ((((((occ_k_h_fused / 3) * 108) + (icb * 9)) + ((occ_k_h_fused % 3) * 3)) + k_w))+(27*2), ((((((occ_k_h_fused / 3) * 108) + (icb * 9)) + ((occ_k_h_fused % 3) * 3)) + k_w))+(27*3));\n",
      "        *(float4*)(((float*)data_vec) + (((occ_k_h_fused * 36) + (k_w * 12)) + (icb * 4))) = (float4(((float*)p1_1)[v__1.s0],((float*)p1_1)[v__1.s1],((float*)p1_1)[v__1.s2],((float*)p1_1)[v__1.s3]));\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  for (int32_t ax0_ax1_outer_fused_ax2_fused = 0; ax0_ax1_outer_fused_ax2_fused < 128; ++ax0_ax1_outer_fused_ax2_fused) {\n",
      "    float4 conv2d_NCHWc[32];\n",
      "    float4 conv2d_NCHWc_global[16];\n",
      "    for (int32_t ow_outer = 0; ow_outer < 2; ++ow_outer) {\n",
      "      conv2d_NCHWc_global[0] = ((float4)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      conv2d_NCHWc_global[1] = ((float4)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      conv2d_NCHWc_global[2] = ((float4)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      conv2d_NCHWc_global[3] = ((float4)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      conv2d_NCHWc_global[4] = ((float4)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      conv2d_NCHWc_global[5] = ((float4)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      conv2d_NCHWc_global[6] = ((float4)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      conv2d_NCHWc_global[7] = ((float4)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      conv2d_NCHWc_global[8] = ((float4)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      conv2d_NCHWc_global[9] = ((float4)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      conv2d_NCHWc_global[10] = ((float4)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      conv2d_NCHWc_global[11] = ((float4)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      conv2d_NCHWc_global[12] = ((float4)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      conv2d_NCHWc_global[13] = ((float4)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      conv2d_NCHWc_global[14] = ((float4)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      conv2d_NCHWc_global[15] = ((float4)(0.000000e+00f, 0.000000e+00f, 0.000000e+00f, 0.000000e+00f));\n",
      "      for (int32_t kh = 0; kh < 3; ++kh) {\n",
      "        for (int32_t kw = 0; kw < 3; ++kw) {\n",
      "          for (int32_t ic_inner = 0; ic_inner < 3; ++ic_inner) {\n",
      "            int32_t cse_var_3 = (((((ax0_ax1_outer_fused_ax2_fused >> 5) * 108) + (kh * 36)) + (kw * 12)) + (ic_inner * 4));\n",
      "            int32_t cse_var_2 = (((((kh * 102) + ((ax0_ax1_outer_fused_ax2_fused & 31) * 102)) + (ow_outer * 48)) + (kw * 3)) + ic_inner);\n",
      "            int32_t4 v__2 = int32_t4((cse_var_3)+(1*0), (cse_var_3)+(1*1), (cse_var_3)+(1*2), (cse_var_3)+(1*3));\n",
      "            conv2d_NCHWc_global[0] = (conv2d_NCHWc_global[0] + (((float4)(((float*)data_pad)[cse_var_2], ((float*)data_pad)[cse_var_2], ((float*)data_pad)[cse_var_2], ((float*)data_pad)[cse_var_2])) * (float4(((float*)data_vec)[v__2.s0],((float*)data_vec)[v__2.s1],((float*)data_vec)[v__2.s2],((float*)data_vec)[v__2.s3]))));\n",
      "            conv2d_NCHWc_global[1] = (conv2d_NCHWc_global[1] + (((float4)(((float*)data_pad)[(cse_var_2 + 3)], ((float*)data_pad)[(cse_var_2 + 3)], ((float*)data_pad)[(cse_var_2 + 3)], ((float*)data_pad)[(cse_var_2 + 3)])) * (float4(((float*)data_vec)[v__2.s0],((float*)data_vec)[v__2.s1],((float*)data_vec)[v__2.s2],((float*)data_vec)[v__2.s3]))));\n",
      "            conv2d_NCHWc_global[2] = (conv2d_NCHWc_global[2] + (((float4)(((float*)data_pad)[(cse_var_2 + 6)], ((float*)data_pad)[(cse_var_2 + 6)], ((float*)data_pad)[(cse_var_2 + 6)], ((float*)data_pad)[(cse_var_2 + 6)])) * (float4(((float*)data_vec)[v__2.s0],((float*)data_vec)[v__2.s1],((float*)data_vec)[v__2.s2],((float*)data_vec)[v__2.s3]))));\n",
      "            conv2d_NCHWc_global[3] = (conv2d_NCHWc_global[3] + (((float4)(((float*)data_pad)[(cse_var_2 + 9)], ((float*)data_pad)[(cse_var_2 + 9)], ((float*)data_pad)[(cse_var_2 + 9)], ((float*)data_pad)[(cse_var_2 + 9)])) * (float4(((float*)data_vec)[v__2.s0],((float*)data_vec)[v__2.s1],((float*)data_vec)[v__2.s2],((float*)data_vec)[v__2.s3]))));\n",
      "            conv2d_NCHWc_global[4] = (conv2d_NCHWc_global[4] + (((float4)(((float*)data_pad)[(cse_var_2 + 12)], ((float*)data_pad)[(cse_var_2 + 12)], ((float*)data_pad)[(cse_var_2 + 12)], ((float*)data_pad)[(cse_var_2 + 12)])) * (float4(((float*)data_vec)[v__2.s0],((float*)data_vec)[v__2.s1],((float*)data_vec)[v__2.s2],((float*)data_vec)[v__2.s3]))));\n",
      "            conv2d_NCHWc_global[5] = (conv2d_NCHWc_global[5] + (((float4)(((float*)data_pad)[(cse_var_2 + 15)], ((float*)data_pad)[(cse_var_2 + 15)], ((float*)data_pad)[(cse_var_2 + 15)], ((float*)data_pad)[(cse_var_2 + 15)])) * (float4(((float*)data_vec)[v__2.s0],((float*)data_vec)[v__2.s1],((float*)data_vec)[v__2.s2],((float*)data_vec)[v__2.s3]))));\n",
      "            conv2d_NCHWc_global[6] = (conv2d_NCHWc_global[6] + (((float4)(((float*)data_pad)[(cse_var_2 + 18)], ((float*)data_pad)[(cse_var_2 + 18)], ((float*)data_pad)[(cse_var_2 + 18)], ((float*)data_pad)[(cse_var_2 + 18)])) * (float4(((float*)data_vec)[v__2.s0],((float*)data_vec)[v__2.s1],((float*)data_vec)[v__2.s2],((float*)data_vec)[v__2.s3]))));\n",
      "            conv2d_NCHWc_global[7] = (conv2d_NCHWc_global[7] + (((float4)(((float*)data_pad)[(cse_var_2 + 21)], ((float*)data_pad)[(cse_var_2 + 21)], ((float*)data_pad)[(cse_var_2 + 21)], ((float*)data_pad)[(cse_var_2 + 21)])) * (float4(((float*)data_vec)[v__2.s0],((float*)data_vec)[v__2.s1],((float*)data_vec)[v__2.s2],((float*)data_vec)[v__2.s3]))));\n",
      "            conv2d_NCHWc_global[8] = (conv2d_NCHWc_global[8] + (((float4)(((float*)data_pad)[(cse_var_2 + 24)], ((float*)data_pad)[(cse_var_2 + 24)], ((float*)data_pad)[(cse_var_2 + 24)], ((float*)data_pad)[(cse_var_2 + 24)])) * (float4(((float*)data_vec)[v__2.s0],((float*)data_vec)[v__2.s1],((float*)data_vec)[v__2.s2],((float*)data_vec)[v__2.s3]))));\n",
      "            conv2d_NCHWc_global[9] = (conv2d_NCHWc_global[9] + (((float4)(((float*)data_pad)[(cse_var_2 + 27)], ((float*)data_pad)[(cse_var_2 + 27)], ((float*)data_pad)[(cse_var_2 + 27)], ((float*)data_pad)[(cse_var_2 + 27)])) * (float4(((float*)data_vec)[v__2.s0],((float*)data_vec)[v__2.s1],((float*)data_vec)[v__2.s2],((float*)data_vec)[v__2.s3]))));\n",
      "            conv2d_NCHWc_global[10] = (conv2d_NCHWc_global[10] + (((float4)(((float*)data_pad)[(cse_var_2 + 30)], ((float*)data_pad)[(cse_var_2 + 30)], ((float*)data_pad)[(cse_var_2 + 30)], ((float*)data_pad)[(cse_var_2 + 30)])) * (float4(((float*)data_vec)[v__2.s0],((float*)data_vec)[v__2.s1],((float*)data_vec)[v__2.s2],((float*)data_vec)[v__2.s3]))));\n",
      "            conv2d_NCHWc_global[11] = (conv2d_NCHWc_global[11] + (((float4)(((float*)data_pad)[(cse_var_2 + 33)], ((float*)data_pad)[(cse_var_2 + 33)], ((float*)data_pad)[(cse_var_2 + 33)], ((float*)data_pad)[(cse_var_2 + 33)])) * (float4(((float*)data_vec)[v__2.s0],((float*)data_vec)[v__2.s1],((float*)data_vec)[v__2.s2],((float*)data_vec)[v__2.s3]))));\n",
      "            conv2d_NCHWc_global[12] = (conv2d_NCHWc_global[12] + (((float4)(((float*)data_pad)[(cse_var_2 + 36)], ((float*)data_pad)[(cse_var_2 + 36)], ((float*)data_pad)[(cse_var_2 + 36)], ((float*)data_pad)[(cse_var_2 + 36)])) * (float4(((float*)data_vec)[v__2.s0],((float*)data_vec)[v__2.s1],((float*)data_vec)[v__2.s2],((float*)data_vec)[v__2.s3]))));\n",
      "            conv2d_NCHWc_global[13] = (conv2d_NCHWc_global[13] + (((float4)(((float*)data_pad)[(cse_var_2 + 39)], ((float*)data_pad)[(cse_var_2 + 39)], ((float*)data_pad)[(cse_var_2 + 39)], ((float*)data_pad)[(cse_var_2 + 39)])) * (float4(((float*)data_vec)[v__2.s0],((float*)data_vec)[v__2.s1],((float*)data_vec)[v__2.s2],((float*)data_vec)[v__2.s3]))));\n",
      "            conv2d_NCHWc_global[14] = (conv2d_NCHWc_global[14] + (((float4)(((float*)data_pad)[(cse_var_2 + 42)], ((float*)data_pad)[(cse_var_2 + 42)], ((float*)data_pad)[(cse_var_2 + 42)], ((float*)data_pad)[(cse_var_2 + 42)])) * (float4(((float*)data_vec)[v__2.s0],((float*)data_vec)[v__2.s1],((float*)data_vec)[v__2.s2],((float*)data_vec)[v__2.s3]))));\n",
      "            conv2d_NCHWc_global[15] = (conv2d_NCHWc_global[15] + (((float4)(((float*)data_pad)[(cse_var_2 + 45)], ((float*)data_pad)[(cse_var_2 + 45)], ((float*)data_pad)[(cse_var_2 + 45)], ((float*)data_pad)[(cse_var_2 + 45)])) * (float4(((float*)data_vec)[v__2.s0],((float*)data_vec)[v__2.s1],((float*)data_vec)[v__2.s2],((float*)data_vec)[v__2.s3]))));\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      for (int32_t ow_inner = 0; ow_inner < 16; ++ow_inner) {\n",
      "        conv2d_NCHWc[((ow_outer * 16) + ow_inner)] = conv2d_NCHWc_global[ow_inner];\n",
      "      }\n",
      "    }\n",
      "    for (int32_t ax3_outer = 0; ax3_outer < 2; ++ax3_outer) {\n",
      "      for (int32_t ax3_inner = 0; ax3_inner < 16; ++ax3_inner) {\n",
      "        int32_t cse_var_5 = (ax0_ax1_outer_fused_ax2_fused >> 5);\n",
      "        int32_t cse_var_4 = (ax3_outer * 16);\n",
      "          int32_t4 v__3 = int32_t4((((((cse_var_5 * 4096) + ((ax0_ax1_outer_fused_ax2_fused & 31) * 32)) + cse_var_4) + ax3_inner))+(1024*0), (((((cse_var_5 * 4096) + ((ax0_ax1_outer_fused_ax2_fused & 31) * 32)) + cse_var_4) + ax3_inner))+(1024*1), (((((cse_var_5 * 4096) + ((ax0_ax1_outer_fused_ax2_fused & 31) * 32)) + cse_var_4) + ax3_inner))+(1024*2), (((((cse_var_5 * 4096) + ((ax0_ax1_outer_fused_ax2_fused & 31) * 32)) + cse_var_4) + ax3_inner))+(1024*3));\n",
      "          float4 v__4 = conv2d_NCHWc[(cse_var_4 + ax3_inner)] + *(float4*)(((float*)p2_1) + (cse_var_5 * 4));\n",
      "          ((float*)T_add_1)[v__3.s0] = v__4.s0;\n",
      "          ((float*)T_add_1)[v__3.s1] = v__4.s1;\n",
      "          ((float*)T_add_1)[v__3.s2] = v__4.s2;\n",
      "          ((float*)T_add_1)[v__3.s3] = v__4.s3;\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  if (TVMBackendFreeWorkspace(1, dev_id, data_pad) != 0) {\n",
      "    return -1;\n",
      "  }\n",
      "  if (TVMBackendFreeWorkspace(1, dev_id, data_vec) != 0) {\n",
      "    return -1;\n",
      "  }\n",
      "  return 0;\n",
      "}\n",
      "\n",
      "// CodegenC: NOTE: Auto-generated entry function\n",
      "#ifdef __cplusplus\n",
      "extern \"C\"\n",
      "#endif\n",
      "TVM_DLL int32_t __tvm_main__(void* args, int* arg_type_ids, int num_args, void* out_ret_value, int* out_ret_tcode, void* resource_handle) {\n",
      "  return tvmgen_default_fused_nn_conv2d_nn_bias_add(args, arg_type_ids, num_args, out_ret_value, out_ret_tcode, resource_handle);\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lib = graph_module.get_lib()\n",
    "print(lib.get_source())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
